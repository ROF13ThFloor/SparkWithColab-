# analyze datasets with Spark 

> in this project I use spark to analyze some datasets contains important data. <br/>
Apache Spark is a data processing framework that can quickly perform processing tasks on very large data sets, and can also distribute data processing tasks across multiple computers, either on its own or in tandem with other distributed computing tools. These two qualities are key to the worlds of big data and machine learning, which require the marshalling of massive computing power to crunch through large data stores. Spark also takes some of the programming burdens of these tasks off the shoulders of developers with an easy-to-use API that abstracts away much of the grunt work of distributed computing and big data processing. <br/>
> if you want to know more about soark see below link :  <br/>
- [Spark Documents ](https://breakdance.github.io/breakdance/) - Spark documentation guide <br/>

